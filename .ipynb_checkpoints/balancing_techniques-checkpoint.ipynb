{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "import csv\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r'PATH TO DIRECTORY WHERE THE ORIGINAL TRAINING DATA IS LOCATED'\n",
    "\n",
    "for subdir, dirs, files in os.walk(path_to_data):\n",
    "                count = 0\n",
    "                if subdir.endswith('training'):\n",
    "                   try:\n",
    "                       for training_file in os.listdir(os.path.join(subdir)):\n",
    "                           f = os.path.join(subdir+ '/' + training_file)\n",
    "                           if 'x_train_lines' in training_file:\n",
    "                                training_data = pd.read_csv(f, sep='$', index_col=False, encoding='utf-8')\n",
    "                                training_data = training_data.drop('class_value', axis= 1)   \n",
    "                                \n",
    "                                # replace the training filename with the class values' filename in the filepath\n",
    "                                f = f.replace('x_train_lines', 'x_train_dep')\n",
    "                                training_data['class_value'] = pd.read_csv(f)\n",
    "\n",
    "                                project_name = subdir.split('/')[-2]\n",
    "                                Balance_SMOTE(data, project_name, str(f[-5]))                                \n",
    "                                NearMiss_data(data, project_name,  str(f[-5]))\n",
    "                                InstanceHardnessThreshold_data(data, project_name,  str(f[-5]))\n",
    "                                EditedNearestNeighbours_data(data, project_name,  str(f[-5]))\n",
    "                                SVMSMOTE_data(data, project_name,  str(f[-5]))\n",
    "                                ADASYN_data(data, project_name,  str(f[-5])) \n",
    "                                Tomek_Links(data, project_name,  str(f[-5]))\n",
    "                               \n",
    "                   except:\n",
    "                        print('an exeption occured') \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tomek_Links(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    X = X.iloc[:, 2:(len(data.columns) - 4)].astype(int)\n",
    "    y = data['class_value'].astype(int)\n",
    "    tl = TomekLinks()\n",
    "    X_resampled, y_resampled = tl.fit_resample(X, y)\n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/tomek_links/balanced_tomek' + \n",
    "                         str(count) +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73765c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADASYN_data(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    X = X.iloc[:, 2:(len(data.columns) - 4)].astype(int)\n",
    "    y = data['class_value'].astype(int)\n",
    "    adasyn = ADASYN()\n",
    "    X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
    "    \n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/adasyn/balanced_adasyn' + \n",
    "                            str(count) +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMSMOTE_data(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    X = X.iloc[:, 2:(len(data.columns) - 4)].astype(int)\n",
    "    y = data['class_value'].astype(int)\n",
    "    svm_smote = SVMSMOTE()\n",
    "    X_resampled, y_resampled = svm_smote.fit_resample(X, y)\n",
    "    \n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/svmsmote/balanced_svm' + \n",
    "                            str(count) +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EditedNearestNeighbours_data(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    X = X.iloc[:, 2:(len(data.columns) - 4)].astype(int)\n",
    "    y = data['class_value'].astype(int)\n",
    "    enn = EditedNearestNeighbours()\n",
    "    X_resampled, y_resampled = enn.fit_resample(X, y)\n",
    "    \n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/editednearestneighbor/balanced_enn' + \n",
    "                            str(count) +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e41b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InstanceHardnessThreshold_data(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    X = X.iloc[:, 2:(len(data.columns) - 4)].astype(int)\n",
    "    y = data['class_value'].astype(int)\n",
    "    iht = InstanceHardnessThreshold()\n",
    "    X_resampled, y_resampled = iht.fit_resample(X, y)\n",
    "    \n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/instancehardness/balanced_ish' + \n",
    "                            str(count) +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NearMiss_data(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    y = data['class_value']\n",
    "    nm = NearMiss()\n",
    "    X_resampled, y_resampled = nm.fit_resample(X.iloc[:, 2:(len(data.columns) - 4)], y)\n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/nearmiss/balanced_nearmiss' + \n",
    "                            str(count) +'.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_SMOTE(data, project_name, count):\n",
    "    X = data.drop('class_value', axis=1)\n",
    "    y = data['class_value']\n",
    "\n",
    "    sm = SMOTE(random_state=42, k_neighbors=2)\n",
    "    X_resampled, y_resampled = sm.fit_resample(X.iloc[:, 2:(len(data.columns) - 4)], y)\n",
    "\n",
    "    \n",
    "    balanced_data = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "    balanced_data.to_csv('PATH TO DIRECTTORY WHERE ALL PROJECT DATA ARE PLACED' + project_name + \n",
    "                         '/training/smote/balanced_smote' + \n",
    "                         str(count) +'.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
